<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Kubernetes on kelvinji2009</title>
    <link>https://kelvinji2009.github.io/categories/kubernetes/</link>
    <description>Recent content in Kubernetes on kelvinji2009</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh</language>
    <lastBuildDate>Sun, 19 Aug 2018 00:57:31 +0800</lastBuildDate>
    
	<atom:link href="https://kelvinji2009.github.io/categories/kubernetes/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>kubernetes最佳实践S01E07：零停机更新集群</title>
      <link>https://kelvinji2009.github.io/blog/k8s-best-practice-s01e07/</link>
      <pubDate>Sun, 19 Aug 2018 00:57:31 +0800</pubDate>
      
      <guid>https://kelvinji2009.github.io/blog/k8s-best-practice-s01e07/</guid>
      <description>kubernetes最佳实践S01E07：零停机更新集群  作者：Sandeep Dinesh, Google Developer Advocate 日期：2018/06/01  原文
编者注：今天是Google Developer Advocate Sandeep Dinesh关于如何充分利用Kubernetes环境的七部分视频和博客系列的最后一部分。
每个人都知道，保持应用程序最新以及优化安全性和性能是一种很好的做法。 Kubernetes和Docker可以更轻松地执行这些更新，因为您可以使用更新构建新容器并相对轻松地部署它。
就像您的应用程序一样，Kubernetes不断获得新功能和安全更新，因此底层节点和Kubernetes基础架构也需要保持最新。
在本期Kubernetes最佳实践中，让我们来看看Google Kubernetes Engine如何让您的Kubernetes集群轻松升级！
集群的两个部分:Master和Node 在升级群集时，需要更新两个部分：Mater和node。 需要首先更新master，node随后。 让我们看看如何使用Kubernetes Engine升级它们。
零停机更新Masters Kubernetes Engine会在发布点发布时会自动升级master，但通常不会自动升级到新版本（例如，1.7到1.8）。 准备好升级到新版本后，只需单击Kubernetes Engine控制台中的升级主按钮即可。
但是，您可能已经注意到该对话框显示以下内容：
“更改主版本可能会导致几分钟的控制平面停机。 在此期间，您将无法编辑此群集。”
当主服务器关闭进行升级时，deployments，services将继续按预期工作。 但是，任何需要Kubernetes API的东西都会停止工作。 这意味着kubectl将停止工作，那些使用Kubernetes API获取有关群集信息的应用程序将停止工作，您基本上无法在集群升级时对群集进行任何更改。
那么如何更新master而不会导致停机呢？
具有Kubernetes Engine区域集群的高可用Masters 虽然标准的zonal Kubernetes Engine集群只有一个master支持它们，但您可以创建regional集群，提供多区域，高可用性的Master。
注意：Kubernetes Engine区域集群最近普遍可用
创建群集时，请务必选择regional选项：
就是这样！ Kubernetes引擎自动在三个zone中创建node和master,master位于负载平衡的IP地址后面，因此Kubernetes API将在升级期间继续工作。
零停机更新Nodes 升级节点时，您可以使用几种不同的策略。 我想关注两个：
 滚动更新 使用节点池迁移  滚动更新 更新Kubernetes node的最简单方法是使用滚动更新。 这是Kubernetes Engine用于更新node的默认升级机制。
滚动更新以下列方式工作。 一个接一个，一个释放，一个锁存，直到该node上不再运行pod。 然后删除该node，并使用更新的Kubernetes版本创建新node。 该node启动并运行后，将更新下一个node。 这一直持续到所有node都更新为止。
您可以通过在节点池(node pool)上启用自动节点升级，让Kubernetes Engine完全为您管理此过程。</description>
    </item>
    
    <item>
      <title>kubernetes最佳实践S01E06：映射外部服务</title>
      <link>https://kelvinji2009.github.io/blog/k8s-best-practice-s01e06/</link>
      <pubDate>Sat, 18 Aug 2018 19:09:26 +0800</pubDate>
      
      <guid>https://kelvinji2009.github.io/blog/k8s-best-practice-s01e06/</guid>
      <description>kubernetes最佳实践S01E06：映射外部服务  作者：Sandeep Dinesh, Google Developer Advocate 日期：2018/05/25  原文
编者按：今天是Google Developer Advocate Sandeep Dinesh关于如何充分利用Kubernetes环境的七部分视频和博客系列的第六部分。
如果您像大多数Kubernetes用户一样，您可能会使用群集外的服务。 例如，您可能使用Twillio API发送短信，或者使用Google Cloud Vision API进行图像分析。
如果您的不同环境中的应用程序连接到同一外部端点，并且没有计划将外部服务引入Kubernetes集群，则可以直接在代码中使用外部服务端点。 但是，在许多情况下情况并非如此。
一个很好的例子是数据库。 虽然某些云原生数据库（如Cloud Firestore或Cloud Spanner）使用单个端点进行所有访问，但大多数数据库都有针对不同实例的单独端点。
此时，您可能认为找到端点的一个好方法是使用ConfigMaps。 只需将端点地址存储在ConfigMap中，并在代码中将其用作环境变量。 虽然这种解决方案有效，但也存在一些缺点。 您需要修改部署以包含ConfigMap并编写其他代码以从环境变量中读取。 但最重要的是，如果端点地址发生更改，则可能需要重新启动所有正在运行的容器以获取更新的端点地址。
在本期“Kubernetes最佳实践”中，让我们学习如何利用Kubernetes的内置服务发现机制来运行集群外部的服务，就像集群内的服务一样！ 这使您可以在dev和prod环境中进行校验，最终只需要在集群中迁移服务，而根本不必更改代码。
场景1：具有IP地址的群集外的数据库 一种非常常见的情况是您托管自己的数据库，但在群集外部执行此操作，例如在Google Compute Engine实例上。 如果您在Kubernetes内部和外部运行某些服务，或者需要比Kubernetes允许的更多自定义或控制，这是非常常见的。
您希望在某些时候，可以迁移集群内的所有服务，但在此之前，您将生活在混合世界中。 值得庆幸的是，您可以使用静态Kubernetes服务来缓解一些痛苦。
在此示例中，我使用Cloud Launcher创建了一个MongoDB服务器。 由于它是在与Kubernetes集群相同的网络（或VPC）中创建的，因此可以使用高性能内部IP地址进行访问。 在Google Cloud中，这是默认设置，因此您无需任何特殊配置。
现在我们有了IP地址，第一步是创建服务：
kind: Service apiVersion: v1 metadata: name: mongo Spec: type: ClusterIP ports: - port: 27017 targetPort: 27017  您可能会注意到此服务没有Pod选择器。 这会创建一个服务，但它不知道在哪里发送流量。 这允许您手动创建将从此服务接收流量的Endpoints对象。
kind: Endpoints apiVersion: v1 metadata: name: mongo subsets: - addresses: - ip: 10.</description>
    </item>
    
    <item>
      <title>kubernetes最佳实践S01E05：优雅地终止</title>
      <link>https://kelvinji2009.github.io/blog/k8s-best-practice-s01e05/</link>
      <pubDate>Sat, 18 Aug 2018 18:39:01 +0800</pubDate>
      
      <guid>https://kelvinji2009.github.io/blog/k8s-best-practice-s01e05/</guid>
      <description>kubernetes最佳实践S01E05：优雅地终止  作者：Sandeep Dinesh, Google Developer Advocate 日期：2018/05/18  原文
编者按：今天是Google Developer Advocate Sandeep Dinesh的七部分视频和博客系列的第五部分，介绍如何充分利用您的Kubernetes环境。
对于分布式系统，处理故障是关键。 Kubernetes通过监视系统状态并重新启动已停止执行的服务的控制器来解决这个问题。 另一方面，Kubernetes通常可以强制终止您的应用程序，作为系统正常运行的一部分。
在本期“Kubernetes最佳实践”中，让我们来看看如何帮助Kubernetes更有效地完成工作并体验下如何减少应用程序停机时间。
在容器出现之前的世界中，大多数应用程序在VM或物理机器上运行。 如果应用程序崩溃，启动替换程序需要很长时间。 如果您只有一台或两台机器来运行应用程序，那么这种恢复时间是不可接受的。
相反，在崩溃时使用进程级监视来重新启动应用程序变得很常见。 如果应用程序崩溃，进程监视可以捕获退出代码并立即重新启动应用程序。
随着像Kubernetes这样的系统的出现，不再需要进程监控系统，因为Kubernetes会重启崩溃的应用程序本身。 Kubernetes使用事件循环来确保容器和节点等资源是健康的。 这意味着您不再需要手动运行这些进程监视器。 如果资源未通过运行状况检查，Kubernetes会自动轮转更换。
查看这一集视频，了解如何为您的服务设置自定义健康检查。
Kubernetes终止生命周期 Kubernetes不仅可以监控应用程序的崩溃。 它可以创建更多应用程序副本，以便在多台计算机上运行，更新应用程序，甚至可以同时运行多个版本的应用程序！
这意味着Kubernetes可以终止一个完全健康的容器有很多原因。 如果您使用滚动更新更新部署，Kubernetes会在启动新pod时慢慢终止旧pod。 如果释放节点，Kubernetes将终止该节点上的所有pod。 如果节点资源不足，Kubernetes将终止pod以释放这些资源
查看第三集，可以了解有关资源的更多信息
重要的是，您的应用程序要优雅地处理终止，以便最终用户受到的影响最小，并且恢复时间尽可能快(Time-to-recovery)！
实际上，这意味着您的应用程序需要处理SIGTERM消息并在收到它时开始关闭。 这意味着你需要保存所有需要保存的数据，关闭网络连接，完成剩下的任何工作以及其他类似任务。
一旦Kubernetes决定终止您的pod，就会发生一系列事件。 让我们看看Kubernetes终止生命周期的每一步。
1.Pod被设置为“终止”状态，并从所有服务的端点列表中删除 此时，pod停止获得新的流量。 在pod中运行的容器不会受到影响。
2. preStop Hook被执行 preStop Hook是一个特殊命令或http请求，发送到pod中的容器。
如果您的应用程序在接收SIGTERM时没有正常关闭，您可以使用此Hook来触发正常关闭。 接收SIGTERM时大多数程序都会正常关闭，但如果您使用的是第三方代码或管理系统则无法控制，所以preStop Hook是在不修改应用程序的情况下触发正常关闭的好方法。
3. SIGTERM信号被发送到pod 此时，Kubernetes将向pod中的容器发送SIGTERM信号。 这个信号让容器知道它们很快就会被关闭。
您的代码应该监听此事件并在此时开始干净地关闭。 这可能包括停止任何长期连接（如数据库连接或WebSocket流），保存当前状态或类似的东西。
即使您使用preStop Hook，如果您发送SIGTERM信号，测试一下应用程序会发生什么情况也很重要，这样您在生产环境中才不会感到惊讶！
4. Kubernetes优雅等待期 此时，Kubernetes等待指定的时间称为优雅终止等待期。 默认情况下，这是30秒。 值得注意的是，这与preStop Hook和SIGTERM信号并行发生。 Kubernetes不会等待preStop Hook完成。</description>
    </item>
    
    <item>
      <title>kubernetes最佳实践S01E04：资源请求和限制</title>
      <link>https://kelvinji2009.github.io/blog/k8s-best-practice-s01e04/</link>
      <pubDate>Sat, 18 Aug 2018 01:42:12 +0800</pubDate>
      
      <guid>https://kelvinji2009.github.io/blog/k8s-best-practice-s01e04/</guid>
      <description>kubernetes最佳实践S01E04：资源请求和限制  作者：Sandeep Dinesh, Google Developer Advocate 日期：2018/05/11  原文
编者按：今天是Google Developer Advocate Sandeep Dinesh关于如何充分利用Kubernetes环境的七部分视频和博客系列的第四部分。
当Kubernetes调度Pod时，容器是否有足够的资源来实际运行是很重要的。 如果大型应用程序被调度到资源有限的节点上，则节点可能会耗尽内存或CPU资源，并且可能会停止工作！
应用程序有可能占用比其应占有的资源更多的资源。 这可能是因为一个团队调整为更多的副本，而不是人工减少延迟（嘿，调整更多副本比让你的代码更高效容易得多！），或者一个错误的配置修改使CPU占用100％，进而导致程序失去控制。 无论问题是由糟糕的开发人员，或者糟糕的代码，亦或是运气不好引起的，重要的是你能掌控你自己。
在本期Kubernetes最佳实践中，让我们来看看如何使用资源请求和限制来解决这些问题。
请求和限制 请求和限制是Kubernetes用于控制CPU和内存等资源的机制。 请求是保证容器能够得到的资源。 如果容器请求资源，Kubernetes会将其调度到可以为其提供该资源的节点上。 另一方面，限制则是确保容器的资源请求永远不会超过某个值。 容器只允许达到限制设定的资源值，无法获得更多资源。
重要的是要记住，限制永远不会低于请求。 如果你试试这个，Kubernetes将抛出一个错误，不会让你运行容器。
请求和限制基于单个容器。 虽然Pod通常包含一个容器，但通常也会看到Pods包含多个容器。 Pod中的每个容器都有自己的限制和请求，但由于Pod总是被认为是一个组，因此您需要将组内每个容器的限制和请求加在一起以获取Pod的聚合值。
要控制容器可以拥有的请求和限制，可以在Container级别和Namespace级别设置配额。 如果您想了解有关命名空间的更多信息，请参阅我们博客系列中的上一篇文章！
让我们看看这些是如何工作的。
容器设置 有两种类型的资源：CPU和内存。 Kubernetes调度程序使用这些来确定运行pod的位置(即哪个节点)。
请点击这里获取这些内容介绍的相关文档
如果您是在Google Kubernetes Engine中运行，则默认名称空间已经为您设置了一些请求和限制。
这些默认设置仅仅适用于Hello World应用，更改成适合您的应用非常重要。
资源的典型Pod spec可能看起来像这样。 这个pod有两个容器：
Pod中的每个容器都可以设置自己的请求和限制，这些都是附加的设置。 因此在上面的示例中，Pod的总请求为500 mCPU，内存为128 MiB，总需求为1 CPU和256MiB。
CPU CPU资源以毫秒定义。 如果您的容器需要运行两个完整的核心，那么您将设置值2000m。 如果您的容器只需要1/4的核心，那么您将设置一个250m的值。
关于CPU请求要记住的一件事是，如果您输入的值大于最大节点的核心数，则永远不会调度您的pod。 假设您有一个需要四个核心的Pod，但您的Kubernetes群集由双核VM组成 - 您的pod将永远不会被调度！
除非您的应用程序专门用于利用多个核心（科学计算和某些数据库），否则通常最好将CPU请求保持在1或更低，并运行更多副本以扩展它。 这为系统提供了更大的灵活性和可靠性。
就CPU限制而言，事情其实很有趣。 CPU被认为是可压缩资源。 如果您的应用程序开始达到您的CPU限制，Kubernetes会开始限制您的容器。 这意味着CPU将受到人为限制，使您的应用程序性能可能更差！ 但是，它不会被终止或退出。 您可以使用liveness探针的运行状况检查来确保性能未受影响。
内存 内存资源以字节为单位定义。 通常，你给内存一个mebibyte值（这基本上与兆字节相同），实际上你可以提供从字节到PB的任何单位。</description>
    </item>
    
    <item>
      <title>kubernetes最佳实践S01E03：设置带readiness和liveness探针的健康检查</title>
      <link>https://kelvinji2009.github.io/blog/k8s-best-practice-s01e03/</link>
      <pubDate>Sun, 12 Aug 2018 23:02:08 +0800</pubDate>
      
      <guid>https://kelvinji2009.github.io/blog/k8s-best-practice-s01e03/</guid>
      <description>kubernetes最佳实践S01E03：设置带readiness和liveness探针的健康检查  作者：Sandeep Dinesh, Google Developer Advocate 日期：2018/05/04  原文
编者按：今天是Google Developer Advocate Sandeep Dinesh关于如何充分利用Kubernetes环境的七部分视频和博客系列的第三部分。
分布式系统很难管理。 一个重要原因是有许多动态部件都为系统运行起作用。 如果一个小部件损坏，系统必须检测它，绕过它并修复它。 这一切都需要自动完成！
健康检查(Health Check)是让系统知道您的应用实例是否正常工作的简单方法。 如果您的应用实例不再工作，则其他服务不应访问该应用或向其发送请求。 相反，应该将请求发送到已准备好的应用程序实例，或稍后重试。 系统还应该能够使您的应用程序恢复健康状态。
默认情况下，当pod中的所有容器启动时，Kubernetes开始向pod发送流量，并在崩溃时重新启动容器。 虽然这在开始时可以“足够好”，但您还可以通过创建自定义运行状况检查来使部署更加健壮。 幸运的是，Kubernetes使这个相对简单，所以没有理由不去这么干！
在本期Kubernetes最佳实践中，让我们了解readiness和liveness探针的细节，何时使用哪种探针，以及如何在Kubernetes集群中进行设置。
健康检查的类型 Kubernetes为您提供两种类型的健康检查，了解两者之间的差异及其用途非常重要。
Readiness Readiness探针旨在让Kubernetes知道您的应用何时准备好其流量服务。 Kubernetes确保readiness探针检测通过，然后允许服务将流量发送到pod。 如果readiness探针开始失败，Kubernetes将停止向该容器发送流量，直到它通过。
Liveness Liveness探针让Kubernetes知道你的应用程序是活着还是死了。 如果你的应用程序还活着，那么Kubernetes就不管它了。 如果你的应用程序已经死了，Kubernetes将删除Pod并启动一个新的替换它。
健康检查是如何提供帮助的？ 让我们看看两个场景，readiness探针和liveness探针可以帮助您构建鲁棒性更强的应用程序。
Readiness 让我们假设您的应用需要一分钟的时间来预热并开始。 即使该过程已启动，您的服务在启动并运行之前也无法运行。 如果要将此部署扩展为具有多个副本，也会出现问题。 新副本在完全就绪之前不应接收流量，但默认情况下，Kubernetes会在容器内的进程启动后立即开始发送流量。 通过使用readiness探针，Kubernetes等待应用程序完全启动，然后才允许服务将流量发送到新副本。
Liveness 让我们假设另一种情况，你的应用程序有一个令人讨厌的死锁情况，导致它无限期挂起并停止提供请求服务。 因为该服务还在运行，默认情况下Kubernetes认为一切正常并继续向已经broken的pod发送请求。 通过使用liveness探针，Kubernetes会检测到应用程序不再提供请求并重新启动有问题的pod。
探针类型 下一步是定义测试readiness和liveness的探针。 有三种类型的探测：HTTP，Command和TCP。 您可以使用它们中的任何一个进行liveness和readiness检查。
HTTP HTTP探针可能是最常见的自定义liveness探针类型。 即使您的应用程序不是HTTP服务，您也可以在应用程序内创建轻量级HTTP服务以响应liveness探针。 Kubernetes去ping一个路径，如果它得到的是200或300范围内的HTTP响应，它会将应用程序标记为健康。 否则它被标记为不健康。
您可以在此处阅读有关HTTP探针的更多信息。
Command 对于Command探针，Kubernetes则只是在容器内运行命令。 如果命令以退出代码0返回，则容器标记为健康。 否则，它被标记为不健康。 当您不能或不想运行HTTP服务时，此类型的探针则很有用，但是必须是运行可以检查您的应用程序是否健康的命令。
您可以在此处阅读有关Command探针的更多信息。
TCP 最后一种类型的探针是TCP探针，Kubernetes尝试在指定端口上建立TCP连接。 如果它可以建立连接，则容器被认为是健康的; 否则被认为是不健康的。</description>
    </item>
    
    <item>
      <title>kubernetes最佳实践S01E02：使用命名空间管理资源</title>
      <link>https://kelvinji2009.github.io/blog/k8s-best-practice-s01e02/</link>
      <pubDate>Sun, 12 Aug 2018 22:19:22 +0800</pubDate>
      
      <guid>https://kelvinji2009.github.io/blog/k8s-best-practice-s01e02/</guid>
      <description>kubernetes最佳实践S01E02：使用命名空间管理资源  作者：Sandeep Dinesh, Google Developer Advocate 日期：2018/04/27  原文
编者注：今天是Google Developer Advocate Sandeep Dinesh的七部分视频和博客系列的第二部分，介绍如何充分利用您的Kubernetes环境。
当您开始在Kubernetes之上构建越来越多的服务时，简单的任务开始变得更加复杂。 例如，团队无法创建具有相同名称的Kubernetes Service或Deployment。 如果你有成千上万的Pod，只是列出它们都需要一些时间，更不用说实际管理它们了!当然，这些还只是冰山一角。
在本期Kubernetes最佳实践中，让我们来看看如何使用Kubernetes命名空间来更轻松地管理您的Kubernetes资源。
什么是命名空间(Namespace)? 您可以将命名空间视为Kubernetes集群中的虚拟集群。 您可以在单个Kubernetes集群中拥有多个名称空间，并且它们在逻辑上彼此隔离。 他们可以为您和您的团队提供组织，安全甚至性能方面的帮助！
默认命名空间(Default Namespace) 在大多数Kubernetes发行版中，集群开箱即用，名称空间默认为default。事实上，Kubernetes实际上有三个名称空间：default，kube-system（用于Kubernetes组件）和kube-public（ 用于公共资源）。 kube-public现在并没有真正使用过，而且通常单独隔离一个kube-system是个好主意，尤其是在Google Kubernetes Engine这样的托管系统中。 默认名称空间是你创建服务和应用程序的默认位置，如果你不指定namespace参数的话。
这个命名空间绝对没有什么特别之处，除了Kubernetes工具是开箱即用的设置使用这个命名空间外，而且你无法删除它。 虽然它很适合入门和小型生产系统，但我建议不要在大型生产系统中使用它。 这是因为团队很容易在没有意识到的情况下，意外地覆盖或破坏其他服务。 相反，我们应该创建多个名称空间并使用它们来将服务划分为可管理的块。
创建命名空间 不要害怕创建名称空间。 它们不会增加性能损失，而且实际上，在许多情况下它们可以提高性能，因为这样的话Kubernetes API使用的是较小的对象集合。
可以使用单个命令来创建命名空间。 如果你想创建一个名为test的命名空间，你可以运行如下命令：
kubectl create namespace test  或者您可以像创建其他任何Kubernetes资源一样，创建一个YAML文件并应用它。
test.yaml:
kind: Namespace apiVersion: v1 metadata: name: test labels: name: test  kubectl apply -f test.yaml  查看命名空间 您可以使用以下命令查看所有命名空间：
kubectl get namespace  如上图，您可以看到三个内置命名空间，以及名为test的新命名空间。</description>
    </item>
    
    <item>
      <title>Kubernetes最佳实践S01E01：如何以及为什么构建尽量小的容器镜像</title>
      <link>https://kelvinji2009.github.io/blog/k8s-best-practice-s01e01/</link>
      <pubDate>Fri, 10 Aug 2018 14:26:18 +0800</pubDate>
      
      <guid>https://kelvinji2009.github.io/blog/k8s-best-practice-s01e01/</guid>
      <description>Kubernetes最佳实践S01E01：如何以及为什么构建尽量小的容器镜像  作者：Sandeep Dinesh,Google Developer Advocate 日期：2018/04/20  原文
编者按：今天是Google Developer Advocate Sandeep Dinesh 关于如何充分利用Kubernetes环境的七部分视频和博客系列的第一部分。 今天，他主要讲保持容器镜像尽可能小的理论和实用性。
Docker使构建容器镜像变得轻而易举。只需将标准 Dockerfile 放入您的文件夹，运行 docker build 命令，然后运行，芝麻开门！您的容器镜像已构建成功！
这种简单性的缺点是，很容易构建出大体积的容器镜像，其中包含您不需要的东西 - 包括潜在的安全漏洞。
在本期“Kubernetes最佳实践”中，让我们探讨如何使用Alpine Linux 和 Docker builder 模式创建生产就绪的容器镜像，然后做一些基准测试，然后确定这些容器在Kubernetes集群中运行方式。
根据您使用的是解释型语言还是编译型语言，创建容器镜像的过程会有所不同。让我们一起来深入了解！
解释型语言的容器化 解释型语言，如Ruby，Python，Node.js，PHP和其他语言通过发送源代码到解释器来运行代码。 这样的好处是可以跳过编译步骤，但其缺点是要求您将解释器与代码一起丢进去。
幸运的是，大多数这些语言都提供了预构建的Docker容器，其中包含一个轻量级环境，允许您运行更小的容器。
我们来看一个Node.js应用程序并对其进行容器化。 首先，让我们使用node：onbuild镜像作为基础。 Docker容器的onbuild版本预先打包了您需要的所有内容，因此无需执行大量配置即可搞定。 这意味着Dockerfile非常简单（只有两行！）。 但是你要付出的磁盘大小代价 - 差不多700MB！
FROM node:onbuild EXPOSE 8080  通过使用较小的基础镜像（如Alpine），您可以显著减少容器的大小。Alpine Linux是一款体积小，轻量级的Linux发行版，在Docker用户中非常受欢迎，因为它与许多应用程序兼容，同时仍然保持小体积。
幸运的是，Node.js（以及其他流行语言）有一个官方的Alpine图像，可以满足您的一切需求。与默认的node镜像不同，node：alpine会删除许多文件和程序，只留下足以运行您的应用程序的部分。
基于Alpine Linux的Dockerfile创建起来有点复杂，因为你必须运行一些针对onbuild的命令。
FROM node:alpine WORKDIR /app COPY package.json /app/package.json RUN npm install --production COPY server.js /app/server.js EXPOSE 8080 CMD npm start  但是，这是值得的，因为产生的镜像只有65MB！</description>
    </item>
    
    <item>
      <title>Kubernetes最佳实践：第一季概览</title>
      <link>https://kelvinji2009.github.io/blog/k8s-best-practice-s01/</link>
      <pubDate>Fri, 10 Aug 2018 14:19:42 +0800</pubDate>
      
      <guid>https://kelvinji2009.github.io/blog/k8s-best-practice-s01/</guid>
      <description>Kubernetes最佳实践：第一季概览  作者：Sandeep Dinesh,Google Developer Advocate  原文
Kubernetes很复杂，而且每天都变得越来越复杂。如果你是刚开始使用Kubernetes，或者已经在生产环境中运行了一段时间，那么很难跟上正在进行的快速开发步伐。当你有一个团队的人构建在kubernetes的时候，那么想要跟上其快速开发的步伐则显得更加艰难了，因为你必须保证团队里的每个人都保持更新且能同步到生产环境。
虽然市面上有大量的hello world经验的内容，但是使用kubernetes更多涉及到的是如何运行一个Deployment并通过Service把它暴露给外部世界。Kubernetes本身是白纸一张，基本上可以画任何你想画的东西上去，但是想知道从哪开始画却真的相当困难。
考虑到这一点，我开始根据我在日常与人交谈时收到的问题和反馈，开展题为“Kubernetes最佳实践”（以下是幻灯片和视频）的演讲。这个演讲非常受欢迎，我决定深入研究各个主题。我最初为这次演讲制作了七集内容（我想七集是非常合适的数量），我真的认为这些文章和视频可以帮助你和你的团队迅速提升Kubernetes。
所以这里是全部七集期待给你带来观赏乐趣的视频！ 我现在正在制作下一批视频，并希望得到您对想要观看的内容的反馈。欢迎发表评论或在推特上给我发消息，提出您的建议！
第一季  第一季全部视频  S01E01-如何以及为什么要构建尽量小的容器 在使用Kubernetes之前，你必须构建一些容器。Docker使得构建容器变得非常容易，但这也意味着很容易构建低效且不安全的容器。构建较小的容器可以很容易地提高Kubernetes集群的使用效率，而且这是一种不费力的方式。
 博客 视频  S01E02-使用namespace来组织你的资源 一旦过了学习Hello world的阶段，在开始尝试管理在Kubernetes上运行的微服务时，您可能会遇到如何组织它们的问题。随着您的团队的成长并且您需要更多的可见性和控制权时，这会变得更糟。命名空间(namespace)提供了一种管理Kubernetes资源的强大方法，并为k8s的策略和管理提供了基础。
 博客 视频  S01E03-使用readiness和liveness探针来做健康检查 要创建强大可靠的服务需要支持健康检查。虽然Kubernetes具有默认的内置运行状况检查，但它们对于许多应用程序来说可能还不够。 readiness和liveness探针使您能够轻松地为您的应用程序自定义这些运行状况检查。
 博客 视频  S01E04-资源请求和限制 内存泄漏，死循环，未知捣乱分子，过度配置，OMG，这种种问题！虽然Kubernetes为您提供了一个运行服务的强大平台，但如果您没有围绕资源定义规则，那么您最终将陷入困境。 但是值得庆幸的是，Kubernetes为您提供了大量的对资源及其使用方式的控制接口。
 博客 视频  S01E05-优雅终止 Kubernetes中的Pod和Containers需要优雅地处理终止。 Kubernetes可以出于各种原因决定终止一个完全健康的Pod，并且干净地关闭是为您的用户提供良好体验的关键。
 博客 视频  S01E06-映射外部服务 有可能您的服务存在于Kubernetes集群之外。其中一些可能是第三方服务，其他可能是您的团队或公司运行的服务。无论如何，生活在混合世界中会带来复杂性。Kubernetes能够映射这些外部服务，使其感觉就像是Kubernetes本地服务一样，从而更容易消除与外部服务一起工作的距离。
 博客 视频  S01E07-零停机升级集群 您需要做的最重要的事情之一是让您的群集保持最新状态。使用像GKE这样的托管服务可以使这更容易，但是你也可以使用一些其他方法使升级过程更加顺畅。
 博客 视频  从内容审阅到视频和博客编辑团队，感谢所有使这一切成为可能的人，使这个系列成为现实！</description>
    </item>
    
    <item>
      <title>Kubernetes101</title>
      <link>https://kelvinji2009.github.io/blog/kubernetes101/</link>
      <pubDate>Tue, 31 Jul 2018 12:07:48 +0800</pubDate>
      
      <guid>https://kelvinji2009.github.io/blog/kubernetes101/</guid>
      <description>Kubernetes 101 原文链接
几个星期前，我的工作任务变得很有趣：部署Kubernetes集群并编写相关工具，以便开发人员可以在他们正在处理的分支中部署代码，并测试其更改。
在那之前，我一直想学习Kubernetes，因为它听起来很有意思（如果你是希腊人，你会觉得这个名字很有问题），但我从来没有机会，因为我没有任何东西需要运行在集群中。所以，这次我抓住机会，开始查资料，但所有的资料（包括官方教程）似乎太冗长，结构也不合理，所以我有点沮丧。
无论如何，经过几天的研究，事情终于有点眉目了，我开始疯狂在不同的机器上部署，迅速让我的AWS账单暴增了数千美元，这才像一个2018年的有自尊的后端开发人员。因为我的简历现在说自己是个“Kubernetes专家”，一个想法立刻诞生了：为什么不把我对这个系统的宽泛理解以及我已经耗费了几个小时的研究所收集的知识让更多人看到？虽然我无法说服自己不应该再写另一篇漫无目的的文章，但是我很快就明白了：
这就是那篇文章。
我在现有文章中遇到的主要问题是，在深入研究具体细节之前，我找不到的任何内容总结了这些组件是什么以及它们如何组合起来的高级概述。 而这种高屋建瓴的呈现方式是我学习最好的方式。我是以这种方式来写的，希望它也适合你。如果你知道任何描述了Kubernetes如何工作，而且让人容易理解的专家级的文章/教程，请不要告诉我，因为你在我需要你的时候你在哪里，现在我写了我的文章而你却没有及早把它拿出来。
另外请记住，我实际上只学习了Kubernetes一个星期左右，所以学得不会非常深入，有些可能是不准确的，尽管希望没有什么错误，这里的信息应该足够让你达到运行简单集群的程度。
话虽如此，最后我发现Kubernetes中的概念还是非常简单的，虽然我确信有很多东西我还不知道。但是，我知道的事情就足以建立一个集群并让我们的应用在其上运行，而且我很确定它们足以让大多数人知道如何开始。
基本概念 我们需要做的第一件事是详细介绍Kubernetes的各个部分：
 控制平面(Control plane)：顾名思义，这是控制其他一切的部分，这也是我一无所知的部分，因为我们只是向亚马逊付费，让亚马逊帮我们处理这部分。我的理解是，这是最好的决定，除非你是谷歌，否则你应该付费给一些公司，让他们为你管理。
 节点(Nodes)：节点本质上就是一台服务器，就像您付费的物理机worker一样。 这是所有代码部署的地方，将裸服务器变成节点的方法是在其上安装Docker，kubelet，kube-proxy和其他一些东西。本文假设您的群集中已有一些worker。
 容器集(Pods)：pod是容器集合。 这是您的代码所在的位置，通常每个容器都有一个pod，尽管您可能希望将一些密切相关的服务放在同一个pod中。 pod在单个节点上运行（但是一个节点可以运行许多pod），这意味着pod中的所有容器将具有相同的IP地址，并且它们可以通过连接到localhost上的彼此端口来相互通信。Pod在部署后无法更新，只能删除或替换它们。
 部署(Deployments)： Deployment是您将pod实际部署到群集的方式。 您可以在没有Deployment的情况下运行pod，但如果没有Deployment，则无法轻松指定所需的副本数量，在失败时自动重新部署pod，回滚到早期状态等。Deployment使代码生命周期管理变得更容易，并且您可以使用它来使Docker镜像在Kubernetes上运行。
 服务(Service)：服务允许您从一个pod打开端口到其他pod，并指定一个pod的DNS名称，以便能够查找并连接到群集中的其他pod。
 入口(Ingress)：Ingresses是你如何告诉你的Ingress控制器（通常是像Traefik这样的web server）向外界暴露什么，以及在哪个路径或主机名上。 入口将https://some-hostname.your-cluster.your-company.com映射到将实际应答该请求的pod。本教程也假设您已经配置了入口，虽然设置Traefik来做到这一点不应该非常困难（在用他们的教程时请使用Deployment方法）。
  所有这些都可以使用命令行的kubectl创建，或者更安全地通过YAML文件创建，该文件将包含您要部署的内容的定义和详细信息（然后执行kubectl apply -f &amp;lt;yaml file&amp;gt;。
概括地讲，您把容器放入pods中，这些pods将由deployment创建和部署，其网络将由service处理，并添加ingress以便外部世界可以访问您的服务器。
让我们逐个介绍这些部分，看看它们的YAML配置是什么样的。
The Pod 让我们看一下将在容器中运行redis镜像的pod的YAML配置。 请记住，pod并不是持久性的，所以你几乎不会直接使用它。 相反，您将使用deployment间接部署pod，我们将在下面介绍。
以下配置示例仅供您进行修改。 你只需要看看它，然后继续阅读，不要停下来惊叹它的美丽。
apiVersion: v1 kind: Pod metadata: name: my-pod-name spec: containers: - name: my-redis image: redis ports: - containerPort: 6379  正如您所看到的，它非常简单，您添加了一堆Kubernetes特定的东西，每个都只是复制粘贴，然后您声明此配置是为Pod，给它一个名称，指定在其中运行的容器和他们监听的端口，请删除整个文件吧，你已经准备好了！</description>
    </item>
    
    <item>
      <title>为何说kubernetes是新一代的应用服务器(译)</title>
      <link>https://kelvinji2009.github.io/blog/why-kubernetes-is-the-new-application-server/</link>
      <pubDate>Wed, 18 Jul 2018 21:53:43 +0800</pubDate>
      
      <guid>https://kelvinji2009.github.io/blog/why-kubernetes-is-the-new-application-server/</guid>
      <description>为何说kubernetes是新一代的应用服务器 原文
你有没有想过为什么你要使用容器部署你的多平台应用程序？这只是“跟随炒作”的问题吗？在本文中，我将要问一些挑衅性的问题，以说明为什么Kubernetes是新一代的应用服务器。
您可能已经注意到大多数语言都是被interpreted并使用runtime来执行您的源代码。 理论上，大多数Node.js，Python和Ruby代码可以轻松地从一个平台（Windows，Mac，Linux）迁移到另一个平台。 Java应用程序更进一步，通过将编译后的Java类转换为字节码，能够在具有JVM（Java虚拟机）的任何地方运行。
Java生态系统提供了一种标准格式，用于分发属于同一应用程序的所有Java类。 您可以将这些类打包为包含嵌入的前端，后端和库的JAR（Java归档），WAR（Web归档）和EAR（企业归档）。 那么我问你：为什么要使用容器来分发你的Java应用程序？ 难道它不应该在环境之间轻松移植吗？
从开发人员的角度回答这个问题并不总是显而易见的。 但请考虑一下您的开发环境以及由它与生产环境之间的差异引起的一些可能问题：
 你使用的是Mac，Windows还是Linux？ 您是否遇到过与&amp;rsquo;\&amp;lsquo;vs&amp;rsquo;/&amp;lsquo;作为文件路径分隔符相关的问题？ 你使用的是什么版本的JDK？ 你是否在开发中使用Java 10，但生产使用JRE 8？ 您是否遇到过JVM差异引入的错误？ 你使用的是什么版本的应用服务器？ 生产环境是否使用相同的配置，安全补丁和库版本？ 在生产部署期间，您是否遇到过由于驱动程序或数据库服务器的版本不同而导致的JDBC驱动程序问题，而在开发环境中却没有出现？ 你有没有遇到当你要求应用服务器管理员创建一个数据源或一个JMS队列的时候，它却包含一个错误的字符？  上述所有问题都是由应用程序外部因素引起的，容器最重要的一点是您可以部署所有应用程序（例如，Linux发行版，JVM，应用程序服务器，库，配置以及您的最终应用程序）在预先构建好的容器中。 另外，执行一个内置了所有内容的容器比将代码移动到生产环境并尝试在不工作时解决差异要容易得多。 由于它很容易执行，因此将同一容器水平扩展多个副本也变得很容易。
强化你的应用 在容器变得非常流行之前，应用程序服务器提供了几个Non-functional requirement，例如安全性，隔离性，容错性，配置管理等。 做个类比，应用程序好比CD，应用程序服务器就好比是CD播放器。
作为开发人员，您将负责遵循预定义的标准，并以特定格式分发应用程序，而另一方面，应用程序服务器将“执行”您的应用程序，并提供可能因不同“品牌”而异的其他功能。 在Java世界中，应用程序服务器提供的企业功能标准最近已在Eclipse基础之下有了新的发展。 基于Eclipse Enterprise for Java（EE4JEclipse Enterprise for Java）的工作已经诞生了Jakarta EE。 （欲了解更多信息，请阅读文章Jakarta EE正式发布或观看DevNation视频Jakarta EE：Java EE的未来。）
继续CD播放器的类比，随着容器的提升，容器镜像已经成为新的CD格式。 事实上，容器镜像只不过是分发容器的格式。（如果您需要更好地处理容器镜像以及它们如何分发，请参阅容器术语的实用介绍。）
当您需要向应用程序添加企业级功能时，才能体会到容器的真正好处。 向容器化应用程序提供这些功能的最佳方式是使用Kubernetes作为它们的平台。 此外，Kubernetes平台为其他项目（如Red Hat OpenShift，Istio和Apache OpenWhisk）提供了良好的基础，可以构建和部署强大的生产级别质量的应用程序。
让我们来探索其中的九个功能：
1-服务发现 服务发现是确定如何连接到某个服务的过程。 要获得容器和云原生应用程序的诸多好处，您需要从容器镜像中隔离配置，以便在所有环境中使用相同的容器镜像。 应用程序的外部化配置是12-factor应用程序的关键原则之一。 服务发现是从运行时环境获取配置信息的方法之一，而不是在应用程序中进行硬编码。 Kubernetes提供开箱即用的服务发现。 Kubernetes还提供ConfigMaps和Secrets以从应用程序容器中隔离配置。 Secerets解决了当您需要存储凭据以连接到运行时环境中的数据库等服务时出现的一些挑战。
使用Kubernetes，不需要使用外部服务器或框架。 尽管您可以通过Kubernetes YAML文件管理每个运行时环境的环境设置，但红帽OpenShift提供了一个GUI和CLI，可以让DevOps团队更容易管理。
2-基本调用 在容器内部运行的应用程序可以通过Ingress访问进行访问 - 换句话说，就是从外部世界到您正在暴露的服务。 OpenShift使用HAProxy提供路由对象，HAProxy具有多种功能和负载均衡策略。 您可以使用路由功能进行滚动部署。 这是一些非常复杂的CI / CD策略的基础。 请参阅下面的“6 - 构建和部署管道”。</description>
    </item>
    
  </channel>
</rss>