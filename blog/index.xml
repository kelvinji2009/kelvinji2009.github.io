<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Blogs on kelvinji2009</title>
    <link>https://kelvinji2009.github.io/blog/</link>
    <description>Recent content in Blogs on kelvinji2009</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh</language>
    <lastBuildDate>Tue, 31 Jul 2018 12:07:48 +0800</lastBuildDate>
    
	<atom:link href="https://kelvinji2009.github.io/blog/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Kubernetes101</title>
      <link>https://kelvinji2009.github.io/blog/kubernetes101/</link>
      <pubDate>Tue, 31 Jul 2018 12:07:48 +0800</pubDate>
      
      <guid>https://kelvinji2009.github.io/blog/kubernetes101/</guid>
      <description>Kubernetes 101 原文链接
几个星期前，我的工作任务变得很有趣：部署Kubernetes集群并编写相关工具，以便开发人员可以在他们正在处理的分支中部署代码，并测试其更改。
在那之前，我一直想学习Kubernetes，因为它听起来很有意思（如果你是希腊人，你会觉得这个名字很有问题），但我从来没有机会，因为我没有任何东西需要运行在集群中。所以，这次我抓住机会，开始查资料，但所有的资料（包括官方教程）似乎太冗长，结构也不合理，所以我有点沮丧。
无论如何，经过几天的研究，事情终于有点眉目了，我开始疯狂在不同的机器上部署，迅速让我的AWS账单暴增了数千美元，这才像一个2018年的有自尊的后端开发人员。因为我的简历现在说自己是个“Kubernetes专家”，一个想法立刻诞生了：为什么不把我对这个系统的宽泛理解以及我已经耗费了几个小时的研究所收集的知识让更多人看到？虽然我无法说服自己不应该再写另一篇漫无目的的文章，但是我很快就明白了：
这就是那篇文章。
我在现有文章中遇到的主要问题是，在深入研究具体细节之前，我找不到的任何内容总结了这些组件是什么以及它们如何组合起来的高级概述。 而这种高屋建瓴的呈现方式是我学习最好的方式。我是以这种方式来写的，希望它也适合你。如果你知道任何描述了Kubernetes如何工作，而且让人容易理解的专家级的文章/教程，请不要告诉我，因为你在我需要你的时候你在哪里，现在我写了我的文章而你却没有及早把它拿出来。
另外请记住，我实际上只学习了Kubernetes一个星期左右，所以学得不会非常深入，有些可能是不准确的，尽管希望没有什么错误，这里的信息应该足够让你达到运行简单集群的程度。
话虽如此，最后我发现Kubernetes中的概念还是非常简单的，虽然我确信有很多东西我还不知道。但是，我知道的事情就足以建立一个集群并让我们的应用在其上运行，而且我很确定它们足以让大多数人知道如何开始。
基本概念 我们需要做的第一件事是详细介绍Kubernetes的各个部分：
 控制平面(Control plane)：顾名思义，这是控制其他一切的部分，这也是我一无所知的部分，因为我们只是向亚马逊付费，让亚马逊帮我们处理这部分。我的理解是，这是最好的决定，除非你是谷歌，否则你应该付费给一些公司，让他们为你管理。
 节点(Nodes)：节点本质上就是一台服务器，就像您付费的物理机worker一样。 这是所有代码部署的地方，将裸服务器变成节点的方法是在其上安装Docker，kubelet，kube-proxy和其他一些东西。本文假设您的群集中已有一些worker。
 容器集(Pods)：pod是容器集合。 这是您的代码所在的位置，通常每个容器都有一个pod，尽管您可能希望将一些密切相关的服务放在同一个pod中。 pod在单个节点上运行（但是一个节点可以运行许多pod），这意味着pod中的所有容器将具有相同的IP地址，并且它们可以通过连接到localhost上的彼此端口来相互通信。Pod在部署后无法更新，只能删除或替换它们。
 部署(Deployments)： Deployment是您将pod实际部署到群集的方式。 您可以在没有Deployment的情况下运行pod，但如果没有Deployment，则无法轻松指定所需的副本数量，在失败时自动重新部署pod，回滚到早期状态等。Deployment使代码生命周期管理变得更容易，并且您可以使用它来使Docker镜像在Kubernetes上运行。
 服务(Service)：服务允许您从一个pod打开端口到其他pod，并指定一个pod的DNS名称，以便能够查找并连接到群集中的其他pod。
 入口(Ingress)：Ingresses是你如何告诉你的Ingress控制器（通常是像Traefik这样的web server）向外界暴露什么，以及在哪个路径或主机名上。 入口将https://some-hostname.your-cluster.your-company.com映射到将实际应答该请求的pod。本教程也假设您已经配置了入口，虽然设置Traefik来做到这一点不应该非常困难（在用他们的教程时请使用Deployment方法）。
  所有这些都可以使用命令行的kubectl创建，或者更安全地通过YAML文件创建，该文件将包含您要部署的内容的定义和详细信息（然后执行kubectl apply -f &amp;lt;yaml file&amp;gt;。
概括地讲，您把容器放入pods中，这些pods将由deployment创建和部署，其网络将由service处理，并添加ingress以便外部世界可以访问您的服务器。
让我们逐个介绍这些部分，看看它们的YAML配置是什么样的。
The Pod 让我们看一下将在容器中运行redis镜像的pod的YAML配置。 请记住，pod并不是持久性的，所以你几乎不会直接使用它。 相反，您将使用deployment间接部署pod，我们将在下面介绍。
以下配置示例仅供您进行修改。 你只需要看看它，然后继续阅读，不要停下来惊叹它的美丽。
apiVersion: v1 kind: Pod metadata: name: my-pod-name spec: containers: - name: my-redis image: redis ports: - containerPort: 6379  正如您所看到的，它非常简单，您添加了一堆Kubernetes特定的东西，每个都只是复制粘贴，然后您声明此配置是为Pod，给它一个名称，指定在其中运行的容器和他们监听的端口，请删除整个文件吧，你已经准备好了！</description>
    </item>
    
    <item>
      <title>七个构建容器的最佳实践(译)</title>
      <link>https://kelvinji2009.github.io/blog/7-best-practices-for-building-containers/</link>
      <pubDate>Mon, 23 Jul 2018 14:21:17 +0800</pubDate>
      
      <guid>https://kelvinji2009.github.io/blog/7-best-practices-for-building-containers/</guid>
      <description>七个构建容器的最佳实践(译) 原文
七个构建容器的最佳实践 Kubernetes Engine是大规模运行工作负载的好地方。但在使用Kubernetes之前，您需要将应用程序容器化。您可以在Docker容器中运行大多数应用程序而不会有太多麻烦。但是，在生产中有效地运行这些容器并简化构建过程是另一回事。有许多事情需要注意，这样才能使您的安全团队和运营团队更加放心。本文提供了有助于您有效构建容器的小技巧和最佳实践。
1.每个容器只包含一个应用程序 获取更多细节
当只有一个应用程序在里面运行时，容器的效果最佳。此应用程序应具有单个父进程。例如，不要在同一容器中运行PHP和MySQL：更难调试，Linux信号将无法正确处理，无法水平扩展PHP容器等原因。这使您可以将应用程序的生命周期和该容器绑定在一起。
上图中左边的容器遵循最佳实践，右边的容器没有。
2.正确处理PID 1，信号处理和僵尸进程 获取更多细节
Kubernetes和Docker将Linux信号发送到容器内的应用程序以停止它，使用进程标识符（PID）1将这些信号发送到指定进程。如果您希望应用程序在需要时正常停止，则需要正确地处理这些信号。
谷歌开发者提倡的Sandeep Dinesh的文章-Kubernetes最佳实践：如何优雅终止kubernetes - 解释了整个Kubernetes终止生命周期。
3.优化Docker构建缓存 获取更多细节
Docker可以缓存镜像层以加速以后的构建。这是一个非常有用的功能，但在编写Dockerfiles时，需要介绍一下我们需要考虑的一些行为。 例如，您应该在Dockerfile中尽可能晚地添加应用程序的源代码，以便基本镜像和应用程序的依赖项得到缓存，并且不会在每次构建时重建。
以下面这个Dockerfile为例：
FROM python:3.5 COPY my_code/ /src RUN pip install my_requirements  你应该把最后两行交换一下：
FROM python:3.5 RUN pip install my_requirements COPY my_code/ /src  在新版本中，pip命令的结果将被缓存，并且每次源代码更改时都不会重新运行。
4.删除不必要的工具 获取更多细节
减少主机系统的攻击面总是一个好主意，而且使用容器比使用传统系统容易得多。从容器中删除应用程序不需要的所有内容。 或者更好的处理是，仅将您的应用程序包含在distroless或scratch镜像中。 如果可能，您还应该将容器的文件系统设置为只读。这样在您的绩效考核期间可以从安全团队获得一些出色的反馈。
5.尽可能地构建最小的镜像 获取更多细节
谁喜欢下载数百兆的无用数据？大家都想获取最小的镜像。这样可以减少下载时间，冷启动时间和磁盘使用量。您可以使用多种策略来实现这一目标：从最小的基本镜像开始，利用镜像之间的公共层，并利用Docker的多阶段构建功能。
上图展示了Docker多阶段构建过程。
谷歌开发者提倡的Sandeep Dinesh的文章-Kubernetes最佳实践：如何以及为何构建小型容器镜像 - 深入介绍了这一主题。
6.正确地给镜像打标签 获取更多细节
标签可以帮助用户选择他们想要使用的镜像版本。给镜像打标签主要有两种方法：语义版本控制，或使用Git提交哈希。 无论您选择哪个，必须记录好，并清楚地符合用户的期望。 注意：虽然用户希望某些标签（如“latest”标签）从一个镜像移动到另一个镜像，但他们希望其他标签是不可变的，即使它们在技术上并非如此。 例如，一旦您使用“1.2.3”之类的标签标记了特定版本的镜像，就不应该再移动此标记。
7.仔细考虑是否使用公共镜像 获取更多细节
当你开始使用某个特定的软件时，使用公共镜像是个不错的选择。 但是，在生产中使用它们可能会带来一系列挑战，特别是在约束高的环境中。 例如，您可能需要控制其中的内容，或者您可能不想依赖外部存储库。 另一方面，为您使用的每个软件都构建自己的镜像并非易事，尤其是因为您需要跟上上游软件的安全更新。仔细权衡每种选择的优缺点，并做出明智的决定。</description>
    </item>
    
    <item>
      <title>为何说kubernetes是新一代的应用服务器(译)</title>
      <link>https://kelvinji2009.github.io/blog/why-kubernetes-is-the-new-application-server/</link>
      <pubDate>Wed, 18 Jul 2018 21:53:43 +0800</pubDate>
      
      <guid>https://kelvinji2009.github.io/blog/why-kubernetes-is-the-new-application-server/</guid>
      <description>为何说kubernetes是新一代的应用服务器 原文
你有没有想过为什么你要使用容器部署你的多平台应用程序？这只是“跟随炒作”的问题吗？在本文中，我将要问一些挑衅性的问题，以说明为什么Kubernetes是新一代的应用服务器。
您可能已经注意到大多数语言都是被interpreted并使用runtime来执行您的源代码。 理论上，大多数Node.js，Python和Ruby代码可以轻松地从一个平台（Windows，Mac，Linux）迁移到另一个平台。 Java应用程序更进一步，通过将编译后的Java类转换为字节码，能够在具有JVM（Java虚拟机）的任何地方运行。
Java生态系统提供了一种标准格式，用于分发属于同一应用程序的所有Java类。 您可以将这些类打包为包含嵌入的前端，后端和库的JAR（Java归档），WAR（Web归档）和EAR（企业归档）。 那么我问你：为什么要使用容器来分发你的Java应用程序？ 难道它不应该在环境之间轻松移植吗？
从开发人员的角度回答这个问题并不总是显而易见的。 但请考虑一下您的开发环境以及由它与生产环境之间的差异引起的一些可能问题：
 你使用的是Mac，Windows还是Linux？ 您是否遇到过与&amp;rsquo;\&amp;lsquo;vs&amp;rsquo;/&amp;lsquo;作为文件路径分隔符相关的问题？ 你使用的是什么版本的JDK？ 你是否在开发中使用Java 10，但生产使用JRE 8？ 您是否遇到过JVM差异引入的错误？ 你使用的是什么版本的应用服务器？ 生产环境是否使用相同的配置，安全补丁和库版本？ 在生产部署期间，您是否遇到过由于驱动程序或数据库服务器的版本不同而导致的JDBC驱动程序问题，而在开发环境中却没有出现？ 你有没有遇到当你要求应用服务器管理员创建一个数据源或一个JMS队列的时候，它却包含一个错误的字符？  上述所有问题都是由应用程序外部因素引起的，容器最重要的一点是您可以部署所有应用程序（例如，Linux发行版，JVM，应用程序服务器，库，配置以及您的最终应用程序）在预先构建好的容器中。 另外，执行一个内置了所有内容的容器比将代码移动到生产环境并尝试在不工作时解决差异要容易得多。 由于它很容易执行，因此将同一容器水平扩展多个副本也变得很容易。
强化你的应用 在容器变得非常流行之前，应用程序服务器提供了几个Non-functional requirement，例如安全性，隔离性，容错性，配置管理等。 做个类比，应用程序好比CD，应用程序服务器就好比是CD播放器。
作为开发人员，您将负责遵循预定义的标准，并以特定格式分发应用程序，而另一方面，应用程序服务器将“执行”您的应用程序，并提供可能因不同“品牌”而异的其他功能。 在Java世界中，应用程序服务器提供的企业功能标准最近已在Eclipse基础之下有了新的发展。 基于Eclipse Enterprise for Java（EE4JEclipse Enterprise for Java）的工作已经诞生了Jakarta EE。 （欲了解更多信息，请阅读文章Jakarta EE正式发布或观看DevNation视频Jakarta EE：Java EE的未来。）
继续CD播放器的类比，随着容器的提升，容器镜像已经成为新的CD格式。 事实上，容器镜像只不过是分发容器的格式。（如果您需要更好地处理容器镜像以及它们如何分发，请参阅容器术语的实用介绍。）
当您需要向应用程序添加企业级功能时，才能体会到容器的真正好处。 向容器化应用程序提供这些功能的最佳方式是使用Kubernetes作为它们的平台。 此外，Kubernetes平台为其他项目（如Red Hat OpenShift，Istio和Apache OpenWhisk）提供了良好的基础，可以构建和部署强大的生产级别质量的应用程序。
让我们来探索其中的九个功能：
1-服务发现 服务发现是确定如何连接到某个服务的过程。 要获得容器和云原生应用程序的诸多好处，您需要从容器镜像中隔离配置，以便在所有环境中使用相同的容器镜像。 应用程序的外部化配置是12-factor应用程序的关键原则之一。 服务发现是从运行时环境获取配置信息的方法之一，而不是在应用程序中进行硬编码。 Kubernetes提供开箱即用的服务发现。 Kubernetes还提供ConfigMaps和Secrets以从应用程序容器中隔离配置。 Secerets解决了当您需要存储凭据以连接到运行时环境中的数据库等服务时出现的一些挑战。
使用Kubernetes，不需要使用外部服务器或框架。 尽管您可以通过Kubernetes YAML文件管理每个运行时环境的环境设置，但红帽OpenShift提供了一个GUI和CLI，可以让DevOps团队更容易管理。
2-基本调用 在容器内部运行的应用程序可以通过Ingress访问进行访问 - 换句话说，就是从外部世界到您正在暴露的服务。 OpenShift使用HAProxy提供路由对象，HAProxy具有多种功能和负载均衡策略。 您可以使用路由功能进行滚动部署。 这是一些非常复杂的CI / CD策略的基础。 请参阅下面的“6 - 构建和部署管道”。</description>
    </item>
    
    <item>
      <title>为多个PHP-FPM容器量身打造单一Nginx镜像(译)</title>
      <link>https://kelvinji2009.github.io/blog/%E4%B8%BA%E5%A4%9A%E4%B8%AAphp-fpm%E5%AE%B9%E5%99%A8%E9%87%8F%E8%BA%AB%E6%89%93%E9%80%A0%E5%8D%95%E4%B8%80nginx%E9%95%9C%E5%83%8F%E8%AF%91/</link>
      <pubDate>Wed, 06 Jun 2018 16:00:00 +0800</pubDate>
      
      <guid>https://kelvinji2009.github.io/blog/%E4%B8%BA%E5%A4%9A%E4%B8%AAphp-fpm%E5%AE%B9%E5%99%A8%E9%87%8F%E8%BA%AB%E6%89%93%E9%80%A0%E5%8D%95%E4%B8%80nginx%E9%95%9C%E5%83%8F%E8%AF%91/</guid>
      <description>为多个PHP-FPM容器量身打造单一Nginx镜像 译者的话：这篇博客主要讲述了如何创建一个可以关联docker环境变量与nginx配置文件的nginx镜像，供你所有的PHP-FPM容器应用。
最近我一直在努力部署一套使用Docker容器的PHP微服务。其中一个问题是我们的PHP应用程序被设置为与PHP-FPM和Nginx一起工作（而不是这里所说的简单的Apache/PHP设置）,因此每个PHP微服务需要两个容器（也就是相当于两个Docker镜像）： * PHP-FPM容器 * Nginx容器
假设一个应用运行超过六个PHP微服务，算上你的dev和prod环境，那么最终差不多会产生接近30个容器。我决定构建一个单独的Nginx Docker镜像，将PHP-FPM主机名作为环境变量映射到这个镜像里面独特的配置文件中，而不是为每个PHP-FPM微服务的镜像构建独特的Nginx镜像。
在这篇博客文章中，我将概述我从上述方法1到方法2的过程，最后用介绍如何使用新定制Nginx Docker镜像的解决方案来结束这篇博客。
我已经将这个镜像开源Github，所以如果这刚好是您经常遇到的问题，请随时查看。
为什么是Nginx？ PHP-FPM和Nginx一起使用可以产生更好的PHP应用程序性能，但缺点是PHP-FPM Docker镜像默认没有像PHP Apache镜像那样与Nginx捆绑在一起。 如果您想将Nginx容器连接到PHP-FPM后端，则需要将该后端的DNS记录添加到您的Nginx配置中。
例如，如果PHP-FPM容器作为名为php-fpm-api的容器运行，那么您的Nginx配置文件应该这样写：
location ~ \.php$ { fastcgi_split_path_info ^(.+\.php)(/.+)$; # This line passes requests through to the PHP-FPM container fastcgi_pass php-fpm-api:9000; fastcgi_index index.php; include fastcgi_params; fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name; fastcgi_param PATH_INFO $fastcgi_path_info; }  如果你只服务一个PHP-FPM容器应用，在你的Nginx容器的配置文件中硬编码对应的名字是可以的。但是，如我上面提到的，每个PHP服务都需要一个对应的Nginx容器，我们就需要运行多个Nginx容器。创建一个新的Nginx镜像（我们后面必须维护和升级）将是一件痛苦的事情，因为即使管理一堆不同的卷，对于更改单个变量名称似乎也有很多工作要做。
第一个解决方案：使用Docker文档里提到的方法envsubst 起初，我认为这很容易。在Docker文档中关于如何使用envsubst有一个很好的小章节，但不幸的是，这不适用于我的Nginx配置文件：
vhost.conf
server { listen 80; index index.php index.html; root /var/www/public; client_max_body_size 32M; location / { try_files $uri /index.php?$args; } location ~ \.</description>
    </item>
    
    <item>
      <title>Java和Docker限制的那些事儿(译)</title>
      <link>https://kelvinji2009.github.io/blog/java%E5%92%8Cdocker%E9%99%90%E5%88%B6%E7%9A%84%E9%82%A3%E4%BA%9B%E4%BA%8B%E5%84%BF%E8%AF%91/</link>
      <pubDate>Sun, 27 May 2018 20:00:38 +0800</pubDate>
      
      <guid>https://kelvinji2009.github.io/blog/java%E5%92%8Cdocker%E9%99%90%E5%88%B6%E7%9A%84%E9%82%A3%E4%BA%9B%E4%BA%8B%E5%84%BF%E8%AF%91/</guid>
      <description>Java和Docker限制的那些事儿(译) 原文链接
TLDR; Java和Docker不是天然的朋友。 Docker可以设置内存和CPU限制，而Java不能自动检测到。使用Java的Xmx标识（繁琐/重复）或新的实验性JVM标识，我们可以解决这个问题。
加强Docker容器与Java10集成 - Docker官方博客在最新版本的JAVA的OpenJ9和OpenJDK10中彻底解决了这个问题。
虚拟化中的不匹配 JAVA和Docker的结合并不是完美匹配的，最初的时候离完美匹配有相当大的距离。对于初学者来说，JVM的全部设想就是，虚拟机可以让程序与底层硬件无关。
那么，把我们的java应用打包到JVM中，然后整个再塞进docker容器中，能给我们带来啥好处呢？大多数情况下，你只是在复制JVMs和linux容器，除了浪费更多的内存，没任何好处。感觉这样子挺傻的。
不过，docker可以把你的程序，设置，特定的JDK，linux设置和应用服务器，还有其他工具打包在一起，当做一个东西。站在devops/cloud的角度来看，这样一个完整的容器有着更高层次的封装。
问题一：内存 时至今日，绝大多数产品级应用仍然在使用Java 8（或者更旧的版本），而这可能会带来问题。Java 8(update 131之前的版本)跟docker无法很好地一起工作。问题是在你的机器上，jvm的可用内存和CPU数量并不是docker允许你使用的可用内存和CPU数量。
比如，如果你限制了你的docker容器只能使用100MB内存，但是呢，旧版本的java并不能识别这个限制。JAVA看不到这个限制。JVM会要求更多内存，而且远超这个限制。如果使用太多内存，Docker将采取行动并杀死容器内的进程！JAVA进程被干掉了，很明显，这并不是我们想要的。。。
为了解决这个问题，你需要给java指定一个最大内存限制。在旧版本的JAVA（8u131之前），你需要在容器中通过设置-Xmx来限制堆大小。这感觉不太对，你可不想定义这些限制两次，也不太想在你的容器中来定义。
幸运的是我们现在有了更好的方式来解决这个问题。从JAVA9之后（8u131+），jvm增加了如下标志:
-XX:+UnlockExperimentalVMOptions -XX:+UseCGroupMemoryLimitForHeap  这些标志强制jvm检查linux的cgroup配置，docker是通过cgroup来实现最大内存设置的。现在，如果你的应用到达了docker设置的限制（比如500MB），JVM是可以看到这个限制的。JVM将会尝试GC操作。如果仍然超过内存限制，JVM就会做它该做的事情，抛出OutOfMemoryException。也就是说，JVM能够看到docker的这些设置。
从JAVA10之后（参考下面的测试），这些体验标志位是默认开启的，也可以使用-XX:+UseContainerSupport来使能（你可以通过设置-XX:-UseContainerSupport来禁止这些行为）。
问题二：CPU 第二个问题是类似的，但它与CPU有关。简而言之，JVM将查看硬件并检测CPU的数量。它会优化你的runtime以使用这些CPUs。但是同样的情况，这里还有另一个不匹配，Docker可能不允许你使用所有这些CPUs。可惜的是，这在Java 8或Java 9中并没有修复，但是在Java 10中得到了解决。 从Java 10开始，可用的CPUs的计算将采用以不同的方式（默认情况下）解决此问题（同样是通过UseContainerSupport）。
Java和Docker的内存处理测试 作为一个有趣的练习，让我们验证并测试Docker如何使用几个不同的JVM版本/标志甚至不同的JVM来处理内存不足。
首先，我们创建一个测试应用程序，它只是简单地“吃”内存并且不释放它。
import java.util.ArrayList; import java.util.List; public class MemEat { public static void main(String[] args) { List l = new ArrayList&amp;lt;&amp;gt;(); while (true) { byte b[] = new byte[1048576]; l.add(b); Runtime rt = Runtime.getRuntime(); System.out.println( &amp;quot;free memory: &amp;quot; + rt.</description>
    </item>
    
    <item>
      <title>加强Docker容器与Java10集成(译)</title>
      <link>https://kelvinji2009.github.io/blog/%E5%8A%A0%E5%BC%BAdocker%E5%AE%B9%E5%99%A8%E4%B8%8Ejava10%E9%9B%86%E6%88%90%E8%AF%91/</link>
      <pubDate>Sun, 27 May 2018 01:47:22 +0800</pubDate>
      
      <guid>https://kelvinji2009.github.io/blog/%E5%8A%A0%E5%BC%BAdocker%E5%AE%B9%E5%99%A8%E4%B8%8Ejava10%E9%9B%86%E6%88%90%E8%AF%91/</guid>
      <description>加强Docker容器与Java10集成(译) 原文链接
很多运行在JAVA虚拟机(JVM)中的应用，包括数据服务如Apache Spark和Kafka以及传统企业应用，都运行在容器中。最近，运行在容器里的JVM出现了由于内存和CPU资源限制和使用率导致性能损失问题。这是因为JAVA意识不到自己运行在容器中。随着JAVA 10的发布，JVM终于可以通过设置cgroup来实现这些约束。内存和CPU约束都可以直接在容器里被用来管理JAVA应用，包括： * 在容器里面设置内存约束 * 在容器里设置可用的CPUs个数 * 在容器里设置CPU约束
JAVA 10的这些优化在Docker for mac/windows和Docker企业版均可正常运行。
容器内存限制 一直到JAVA 9，JVM依然不能够通过在容器中使用标识来识别内存或CPU限制。在Java 10中，内存限制可以被自动识别，而且这个特性是默认支持的。
JAVA对服务器进行分级定义，如果一台服务器有2CPUs和2GB内存，那么默认的堆栈大小是1/4的物理内存。假设一个安装了docker企业版的服务器有4CPUs和2GB内存。我们来比较分别比较运行JAVA 8和JAVA 10的容器的区别。先看JAVA 8：
docker container run -it -m512 --entrypoint bash openjdk:latest $ docker-java-home/bin/java -XX:+PrintFlagsFinal -version | grep MaxHeapSize uintx MaxHeapSize := 524288000 {product} openjdk version &amp;quot;1.8.0_162&amp;quot;  我们可以看到最大的堆栈大小是512MB，刚好（1/4）X2GB，只是通过docker EE自动设置的，而不是通过设置容器来实现的。做个比较，我们看下在JAVA 10环境下运行同样的命令是什么结果。
docker container run -it -m512M --entrypoint bash openjdk:10-jdk $ docker-java-home/bin/java -XX:+PrintFlagsFinal -version | grep MaxHeapSize size_t MaxHeapSize = 134217728 {product} {ergonomic} openjdk version &amp;quot;10&amp;quot; 2018-03-20  上面的结果显示，容器里的内存限制非常接近我们期望的128MB。</description>
    </item>
    
  </channel>
</rss>